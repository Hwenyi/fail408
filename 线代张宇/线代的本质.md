---
finished: true
aliases: 
publish: true
url: https://zhuanlan.zhihu.com/p/561986020
title: 线代的本质
tags: []
created: "2024-05-25 07:31"
updated: "2024-09-06 09:58"
---
前言

笔记资料来源

（1）**基本架构**来源于
公众号：大年的资料库
[作者：文哥的学习日记](https://www.jianshu.com/p/2cf54c8a6e5f)
[知乎链接：](https://zhuanlan.zhihu.com/p/457858293)

（2）**视频资料**来源于——B 站

# 一、基础知识

在 正 式 讲 到 线 代 具 体 的 概 念 前 ， 我 们 先 回 忆 一 下 小 学 中 学 时 期 的 数 学 知 识 。

## 1-1：一维空间

一维空间指的是**一条线上所有的点组成的空间**，一般我们会**用数轴作为一种衡量方式**，来描述这条直线上所有的点，换言之，**这条线上所有的点都可以在数轴上表示出来**。

## 1-2：二维空间

二维空间指的是**一个平面空间**，一般我们会**用平面直角坐标系作为衡量方式**，这样一来，**整个平面上所有的点都能用坐标来表示了**。值得注意的是，选择平面直角坐标系，并且规定单位长度为 1，是因为比较方便计算和表示。

事实上，我们还学过**斜坐标系**，平面上**同样一个点，在直角坐标系和斜坐标系中的描述是不一样的，但描述的都是这个点**，就类似于你站在一棵树的右边，一块石头的左边，我以树为参照说你在树的右边，或者以石头为参照说你在石头左边，都没问题。

但具体计算里面，为了简化，我们通常都是选择平面直角坐标系来描述。

## 1-3：三维空间

三维空间指的是**一个立体的空间**，一般我们会**用空间直角坐标系作为衡量方式**，这样，整个三维空间所有的点都能用坐标表示出来了。但同样的，并不是只有空间直角坐标系这一种描述方式，也可以选择不是直角的空间坐标系，但往往这样一来，表示和计算会比较复杂，所以我们一般还是会用空间直角坐标系。

同理，四维五维更高维的空间也是如此，只是这超出了我们能想象的空间，所以就比较难有直观的感受了。

这一部分不是无关内容，对后面理解向量怎么表示，在空间里怎么变换是有意义的。所以希望大家看完能有个大概印象。

# 二、线性代数的用途

如果把空间理解为一个容纳运动的对象集合，那么**线性代数本质上研究的就是线性空间中的【线性变换】**（你可以理解为运动），那**运动的对象就是【向量】**，**运动的方式就是【矩阵】**，所以其实**矩阵是一种线性变换**，**矩阵乘向量表示的就是向量按照某种规则去做线性变换**。矩阵乘向量之后的得到的向量，就是最开始的向量通过线性变换之后的结果。

这个时候你有没有想到另一个概念——函数。

函数的三要素是什么，自变量$x$，对应法则 $f$ 和因变量 $y$ ，自变量 $x$ 经过某种对应法则，变成了 $y$ 。

**“变换”本质上是 “函数” 的一种花哨的说法**，它接收输入内容，并输出对应结果。特别地，在线性代数的情况下，我们考虑的是接收一个向量并且输出一个向量的变换。既然 “变换” 和“函数”意义相同，为什么还要使用前者而不是后者？因为**使用 “变换” 是在暗示以特定方式来可视化这一输入~ 输出关系**。——3blue1brown《线性代数的本质》

你现在对线性代数本质上研究的东西有没有清晰一点。

# 三、基 & 向量 & 张成空间

## 3-1：向量

**向量即我们的研究对象**。

我们的资料给出的定义是有序数组，而**向量在线性空间里就是一个以原点为起点的箭头**。我们的线性变换就是以向量为对象了。

线性代数围绕两种基本运算：**向量加法**和**向量数乘**

<table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><th></th><th>物理观点</th><th>列表观点</th></tr><tr><th>向量的【加法】</th><td>运动</td><td>对应项相加</td></tr><tr><th>向量的【数乘】</th><td>缩放（标量的作用就是缩放）</td><td>分量与标量相乘</td></tr></tbody></table>下面介绍向量的几何意义

考虑平面中的 $x-y$ 坐标系，由 $x$ 轴和 $y$ 轴组成，二者的交叉部分叫做原点。

**一个向量的坐标由一对数组成，这对数指导我们如何从原点走到向量的终点**。

![](https://img.hwenyi.live/202409061758123.webp)

如上图的向量，它告诉我们**先沿** $x$ **轴往左移动 2 个单位，再沿** $y$ **轴移动 3 个方向**。

<table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><td>（1）向量加法的几何意义</td></tr></tbody></table>

假设我们现在有两个向量：

![](https://img.hwenyi.live/202409061758124.webp)

如果我们**把** $\vec{W}$ **从原点移动到** $\vec{{V}}$ **的终点，然后再连接原点和** $\vec{W}$ **的终点**，那么**得到的向量就是二者的和**。

![](https://img.hwenyi.live/202409061758125.webp)

为什么是这样，还是回到向量的意义来，他定义了一种移动方式，假设$\vec{V}$ 的坐标是 [1,2]， $\vec{W}$ 的坐标是 [3,-1]。

$\vec{V}$ 告诉我们要**沿** $x$ **轴向右移动 1 个单位**，**沿** $y$ **轴向上移动 2 个单位**，而 $\vec{W}$ 告诉我们要**沿** $x$ **轴向右移动 3 个单位**，**沿** $y$ **轴向下移动 1 个单位**。这样总体的移动效果就是沿 $x$ 轴向右移动 4 个单位，沿 $y$ 轴向上移动 1 个单位，得到的结果是 [4,1]。

因此**向量加法的几何意义，我们可以看作是多次移动的累积结果**，从计算上来看，就是如下的式子：

![](https://img.hwenyi.live/202409061758126.webp)

<table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><td>（2）向量乘法的几何意义</td></tr></tbody></table>

**向量乘法就是对向量进行拉伸** (乘以一个大于 1 的正数)，**压缩** (乘以一个小于 1 的正数)，**翻转向量的行为** (乘以一个负数)，这些行为统称为统称为 scaling。而**向量乘上的这些数值本身，称之为向量** (scalars)。

向量乘法的计算方式如下：

![](https://img.hwenyi.live/202409061758127.webp)

## 3-2：基

基——描述向量 “**每当我们用数字描述向量，都依赖于我们正在使用的基**。”——3blue1brown

**向量是有序数组**，那么我们用来表示向量的这些数是哪来的，其实依赖于另一个概念——**基**。

**向量空间的一组基是张成该空间的一个线性无关向量集**。我们在线性空间里，也需要有点类似于数轴，平面直角坐标系或者空间直角坐标系这样的一种衡量方式，这里我们是用坐标轴和基来表示，只是这时候我们描述的对象不再是点了，而变成了向量。**任何向量都是其所在线性空间的基的线性组合**。

在一个**二维空间**里，我们选择用来**做坐标系的直线**有什么特点，你可以不是直角，但是你**不能重合也不能平行**，因为这样你就没法确定一个平面了，也就没法描述该平面所有的点了（想想初中的定理，两条相交直线可以确定一个平面）。

同样的，我们**在二维空间用来做基的向量，它必须非零而且不共线（其实就是不相关）**，这样它才能表示该空间所有的向量。如果共线了，它就只能描述这条直线上所有的向量了，而没法描述整个二维空间的向量。同理，三维空间更高维空间也是如此。

你再想想，一维空间我们的数轴是一条直线，二维空间的平面坐标系是两条，三维空间的空间坐标系是三条，那放在线性空间也是一样的，**我们的空间是几维的，基的数量就是几个**。

<table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><th>（1）基向量</th></tr></tbody></table>

上一节介绍了**向量之间两种最基本的运算，向量相加 以及 向量的缩放**。

还是以二维平面为例，其实每一个向量都可以通过**基向量 (basis vectors)** 经由上面的两种运算得到，假设我们的基向量是 [1,0] 和[0,1]，如下图

![](https://img.hwenyi.live/202409061758128.webp)

当然，**基向量可以任意选择**，定义两个向量 $\vec{V}$ 和 $\vec{W}$ ，以其为**基向量，通过加法和乘法，可以得到平面中任意的向量**：

![](https://img.hwenyi.live/202409061758129.webp)

<table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><th>（2）总结</th></tr></tbody></table>

1）线性空间内所有的向量都能由该线性空间的一组基向量线性表示；

2）一般空间是几维，取的基向量的个数就有几个；

3）基向量可以有很多种取法，并不唯一；

4）**一组基向量其实就是极大线性无关组**，再多一个就线性相关了，少一个无法描述空间内所有的向量了，（类似于你没法用数轴表示二维空间所有的点，也没法用平面坐标系表示三维空间所有的点）。

## 3-3：线性组合

**线性组合（Linear Combination）**的几何意义如下图所示

![](https://img.hwenyi.live/202409061758130.webp)

完整上来说，其实是向量之间的线性组合，其主体是向量，**线性组合是一个操作，将各个向量缩放之后，相加在一起，就得到了参与操作的向量之间的线性组合**。

线性组合有下面三种情况：

1）如果**参与组合的一对向量不共线**，那么由它们进行**线性组合所得到的向量可以达到平面上的任意一个点**：

![](https://img.hwenyi.live/202409061758131.webp)

2）如果**参与组合的一对向量共线**，那么由它们进行**线性组合所得到的向量的终点被限制在一条通过原点的直线**：

![](https://img.hwenyi.live/202409061758132.webp)

3）如果**参与组合的一对向量都是零向量**，那么由它们进行**线性组合所得到的向量永远是零向量**：

![](https://img.hwenyi.live/202409061758133.webp)

补充：“线性组合” 的定义

![](https://img.hwenyi.live/202409061758134.webp)

补充：“线性相关”与 “线性无关” 的定义

![](https://img.hwenyi.live/202409061758135.webp)

【注释】以 $S=2$ 的非 0 矩阵为例进行分析。 $S=2$ ，表明系数矩阵的列秩为 2，而要存在非零解，系数矩阵的行列式得等于 0，因此行秩小于列秩，又 $r\geq1$ ，所以此时 $r=1$ ，表明有一个向量是多余的，即二者共线。共线，即线性相关。

## 3-4：张成空间

向量张成的空间：**给定向量** $\vec{V}$ **与** $\vec{W}$ **全部的线性组合所构成的向量集合**。

![](https://img.hwenyi.live/202409061758136.webp)

对于**平面**来说，如果**两个向量不共线，那么可以张成整个二维平面**，如果**共线，只能张成一条直线**。

<table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><th>给定的二维向量</th><th>张成的空间</th></tr><tr><th>1）一般的两个向量</th><td>所有二维向量的集合</td></tr><tr><th>2）两个共线的向量</th><td>一条直线上的向量的集合</td></tr><tr><th>3）两个零向量</th><td>一个点</td></tr></tbody></table>

对于**三维空间**来说，如果**三个向量共线，那么只能张成一条直线**，如果**三个向量共平面，那么只能张成一个平面**，如果**三个向量不共平面，则可以张成整个三维空间**。

<table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><th>给定的向量</th><th>张成的空间</th></tr><tr><th>1）一般的三个向量</th><td>空间中所有的三维向量（平面的扫动）</td></tr><tr><th>2）三个向量，第三个落在前两个所张成的平面上</th><td>平面</td></tr><tr><th>3）三个共线的向量</th><td>一条线</td></tr><tr><th>4）三个零向量</th><td>一个点</td></tr></tbody></table><table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><th>（1）线性相关</th></tr></tbody></table>

**表示方法 1：**如果一组向量中，至少有一个**对张成的空间没有帮助**，或者说其中一个向量**可以表示成其他向量的线性组合**，或者说其中一个向量**在其他向量所张成的向量空间中**，则称它们是线性相关的。

![](https://img.hwenyi.live/202409061758137.webp)

**表示方法 2：**有多个向量，可以**移除之一而不减小张成的空间**，称它们是**线性相关**的。

**表示方法 3：**考研定义

![](https://img.hwenyi.live/202409061758138.webp)

![](https://img.hwenyi.live/202409061758139.webp)

![](https://img.hwenyi.live/202409061758140.webp)

<table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><th>（2）线性无关</th></tr></tbody></table>

所有向量都不能表示成其他向量的线性组合。（以二维为例，就是两个向量不共线）

![](https://img.hwenyi.live/202409061758141.webp)

![](https://img.hwenyi.live/202409061758142.webp)

# 四、矩阵 & 线性变换

## 4-1：线性变换

<table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><th>（1）定义：Linear transformation</th></tr></tbody></table>

变换其实也是一种函数，我们有一个输入向量，然后经过变换之后，得到一个输出向量。

整个过程，可以看作是输入的向量移动到了输出的向量位置。考虑整个平面上的向量，在经过变换之后，得到了一个最新的位置。

![](https://img.hwenyi.live/202409061758143.webp)

<table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><th>（2）线性变换需要满足的条件：</th></tr></tbody></table>

1）变换保持网格线平行且等距分布；

2）所有**直线在变换后仍然保持为直线**，不能有所弯曲；

3）**原点位置必须保持固定**。

<table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><th>（3）如何描述线性变换</th></tr></tbody></table>

考虑向量$\vec{V}=\begin{bmatrix} -1\\2 \end{bmatrix}$ ，在 $\hat{i}=\begin{bmatrix} 1\\0 \end{bmatrix}$ **和** $\hat{j}=\begin{bmatrix} 0\\1 \end{bmatrix}$ **为基**的情况下，$\vec{V}=-1*\hat{i}+2*\hat{j}$ ，假设线性变换如下：

![](https://img.hwenyi.live/202409061758144.webp)

![](https://img.hwenyi.live/202409061758145.webp)

上图中，原先的 $\hat{i}=\begin{bmatrix} 1\\0 \end{bmatrix}$ 变换到 $\hat{i}^{'}= \begin{bmatrix} 1\\-2 \end{bmatrix}$ ，原先的 $\hat{j}= \begin{bmatrix} 0\\1 \end{bmatrix}$ 变换到 $\hat{j}^{'}= \begin{bmatrix} 3\\0 \end{bmatrix}$ ，而原先的 $\vec{V}$ 变换到 $\vec{V}^{'}=\begin{bmatrix} 5\\2 \end{bmatrix}$ ，而关系 $\vec{V}^{'}=-1*\hat{i}^{'}+2*\hat{j}^{'}$ 仍然存在。即图中的式子成立。

所以说，**一个 2*2 的矩阵，** $\begin{bmatrix} a&b\\c&d \end{bmatrix}$ **其实代表了一种线性变换**，它把原来的 $\begin{bmatrix} 1\\0 \end{bmatrix}$ 变换到 $\begin{bmatrix} a\\c \end{bmatrix}$ 的位置，把原先空间中的 $\begin{bmatrix} 0\\1 \end{bmatrix}$ 变换到 $\begin{bmatrix} b\\d \end{bmatrix}$ 的位置。

而该矩阵与一个向量 $\begin{bmatrix} x\\y \end{bmatrix}$ 相乘的结果，相当于对该向量做了一次线性变换，把向量移动到新平面中对应的位置：

![](https://img.hwenyi.live/202409061758146.webp)

![](https://img.hwenyi.live/202409061758147.webp)

## 4-2：矩阵

我们在**用矩阵描述线性变换时，实际上是在描述变换后的基向量坐标**，比如在二维空间里，由于向量 $\vec{V}$ 是 $\hat{i}$ 和$\hat{j}$（$\hat{i}$，$\hat{j}$ 为基）的一个特定线性组合，只要记录了变换后的$\hat{i}$ 和$\hat{j}$，我们就可以推断出任意向量在变换之后的位置，完全不必观察变换本身是什么样。

![](https://img.hwenyi.live/202409061758148.webp)

因为线性变换网格线平行且等距分布，所以**变换前后向量关于基向量的线性组合保持不变**！——3blue1brown

旋转矩阵

![](https://img.hwenyi.live/202409061758149.webp)

剪切矩阵

![](https://img.hwenyi.live/202409061758150.webp)

## 4-3：复合矩阵

**当多个线性变换复合作用于同一个向量的时候，可以通过矩阵复合运算（也就是矩阵乘法）得到一个等效变换**。

矩阵实际上描述（追踪）的是基向量的变换，而**空间内任意向量则是基向量特定的线性组合**。——3blue1brown

![](https://img.hwenyi.live/202409061758151.webp)

两个矩阵相乘的几何意义

两个 $2*2$ 矩阵 $a$ 和 $b$ 相乘，可以看作是对原始空间连续做了两次线性变换，而得到的计算结果 $c$ 也是一个 $2*2$ 的矩阵。

使用 $c$ 对原始空间进行一次线性变换，和连续使用 $a$ 和 $b$ 对原始空间进行两次线性变换的效果相同。

![](https://img.hwenyi.live/202409061758152.webp)

![](https://img.hwenyi.live/202409061758153.webp)

![](https://img.hwenyi.live/202409061758154.webp)

![](https://img.hwenyi.live/202409061758155.webp)

复合矩阵的运算

矩阵复合运算可以类比为函数中的 $f(g(x))$ ，将 $f$ 和 $g$ 复合为一个函数。还记得吗，我们设有 $A$ 和 $B$ 两个矩阵，一般情况下 $AB≠BA$ ，为什么，类比于复合函数之后你就清楚了， $f(g(x))$ 与 $g(f(x))$ 一般情况下并不相等。

![](https://img.hwenyi.live/202409061758156.webp)

两个二阶矩阵相乘的计算

![](https://img.hwenyi.live/202409061758157.webp)

![](https://img.hwenyi.live/202409061758158.webp)

![](https://img.hwenyi.live/202409061758159.webp)

![](https://img.hwenyi.live/202409061758160.webp)

# 五、行列式

如果在二维空间中，我们画出相对应的网格，那么**线性变换，就是对这些网格做了拉伸，收缩或者反转**。那么如何来**定义这种变换的程度**呢？就需要用到**行列式（determinant）**的概念了。

在二维空间中，**行列式是指小正方形（平面任取的，也可以是其他形状）面积的放大率**，对于行列式为负数、为零的情况，可以以动态的方式去理解。

举一个简单的例子吧：

![](https://img.hwenyi.live/202409061758161.webp)

——在进行线性变换后，原来一个面积为 1 的单位方格，变成了面积为 6 的矩形。可以说，线性变换将原空间放大了 6 倍。

**行列式就是线性变换的放大率。**

行列式为零，也就是放大率为 0，在二维空间里，我们本来有个小正方形，好家伙，变换之后面积缩放为 0，什么意思，其实它代表空间被压缩了（比如 3 维被压缩到了 2 维，2 维被压缩到了 1 维），这个二维的平面空间可能被压缩成一条线了，所以放大率为 0 了。

因此**可以通过行列式是否为 0 来判断线性变换后的空间的维度是否与原空间相同**。

![](https://img.hwenyi.live/202409061758162.webp)

![](https://img.hwenyi.live/202409061758163.webp)

为什么 $\left| AB \right|=\left| A \right|\left| B \right|$ ？

**对于确定的线性变换（矩阵）而言，放大率（行列式）都是确定的，无关乎作用于空间的顺序**。

意思是如果线性变换 $AB$ 的放大率如果分别为 1、2，那么不管它们谁先作用于空间，最后得到的等效放大率都是一样的 2。因此就有 **det(AB)=det(A)*det(B)=det(BA)**，这里 $AB$ 和 $BA$ 是两个截然不同的线性变换，但是由于 $AB$ 的放大率是确定并且无关顺序的，所以两者的放大率是一致的。——3blue1brown

![](https://img.hwenyi.live/202409061758164.webp)

行列式的计算

![](https://img.hwenyi.live/202409061758165.webp)

![](https://img.hwenyi.live/202409061758166.webp)

![](https://img.hwenyi.live/202409061758167.webp)

![](https://img.hwenyi.live/202409061758168.webp)

**行列式**提公因式 VS **矩阵**提公因式

![](https://img.hwenyi.live/202409061758169.webp)

![](https://img.hwenyi.live/202409061758164.webp)

![](https://img.hwenyi.live/202409061758171.webp)

# 六、秩

%%o-1920%%
矩阵的秩即**经由该矩阵代表的线性变换后，所形成的空间的维数**。

![](https://img.hwenyi.live/202409061758172.webp)

比如在三维空间中，如果**经过某个矩阵 A 代表的线性变换后**，空间变为一条直线，那么这个矩阵的秩为 1。如果空间变为一个平面，那么这个矩阵的秩为 2。如果还是三维空间，那么矩阵的秩为 3。

![](https://img.hwenyi.live/202409061758173.webp)

![](https://img.hwenyi.live/202409061758174.webp)

**满秩**：秩达到最大值时，意味着秩与列数相等，称之为**满秩。**%%o-1920%%

# 七、线性方程组

我们先从线性方程组着手，一个线性方程组可以表示成 $A·\vec{X}=\vec{V}$ 。

![](https://img.hwenyi.live/202409061758175.webp)

看到这里，你也许已经知道这代表什么含义了，**矩阵** $A$ **相当于一个线性变换，向量** $\vec{X}$ **在经过** $A$ **这个线性变换后，得到的向量为** $\vec{V}$ **。**

线性方程组的**求解过程其实就是找到向量** $\vec{V}$ **在经由** $A$ **这个线性变换之前所在的位置** $\vec{X}$ 。

因此，我们可以把它变成另一个过程，即**将** $\vec{V}$ **所在的线性空间，经过另一个逆向的过程，变回** $\vec{X}$ **所在的线性空间**，那么这个线性变换用矩阵表示，就是 $A$ 的逆矩阵，用 $A^{-1}$ 表示。即逆矩阵 $A^{-1}$ 所代表的线性变换，是 $A$ 所代表的线性变换的逆过程。

因此 $A^{-1}A$ 相对于任何事情都没有做。

![](https://img.hwenyi.live/202409061758176.webp)

![](https://img.hwenyi.live/202409061758177.webp)

那么既然逆矩阵相当于线性变换的逆操作，因此**只有在线性变换后空间的维数不变的情况下，才能进行逆操作**。再结合之前学习到的，**线性变换不降维，前提条件是矩阵的行列式值不为 0**，因此矩阵的**逆矩阵存在的前提，即矩阵的行列式值不为 0**。

![](https://img.hwenyi.live/202409061758178.webp)

**一点小想法**

绿水青山就是金山银山，我们一定要保护好我们所处的自然环境。我们的生命一定程度上是大自然给予的，那么**我们可以看作是以大自然为基向量构成的一个特定组合**，正因为每个人前面的系数不一样，又或者每个人所处的空间维度不同，才造就了独一无二、不可替代的我们。

我们成长的过程，就是一个接一个的线性变换过程，我们的生命是有限的，所以我们会有后来者，他们会接替我们，对我们进行**逆变换**，去解密我们一代又一代人留下的宝贵精神财富与物质财富。

而我们要做的，就是**保证这个线性变换所处的空间不发生质的变化**，给我们的后来者留下足够的发展空间。如此以往，人类的精神文明才能源远流长，绵延千年。

为什么行列式为 0，逆矩阵就不存在了？

行列式的值相当于变换的放大率，如果放大率为 0，就代表空间被压缩了，比如一个线性变换把二维空间压缩成了一维，也就是把某个平面压缩成了一条线，然而你**没法根据这条线把它解压为原来的平面**，因此这时候逆矩阵就不存在了。

我不知道讲清楚了没，可能简单看一遍没法消化，我希望你能多看两遍，通过上述内容，能大概明白向量和矩阵是怎么回事了。

对于方程组进一步的理解

$A·\vec{X}=0$ 可以理解为，向量 $\vec{X}$ 经过 $A$ 变换后与 0 向量重合了。那我们再来看看矩阵 $A$ ，假如它是 3x3 方阵，且**秩为 3。**

（1）**只有零解**：秩为 3 就代表变换后维度是 3，整个变换都在三维空间，没有发生压缩空间，那么显然，只有 0 向量能在空间不发生压缩的情况下变换得到 0 向量。

![](https://img.hwenyi.live/202409061758179.webp)

**（2）存在非零解：**当**秩为 2** 的时候，代表变换后的空间维度为 2，三维空间被压缩到了二维，变换的过程中可能一整条线上的向量都被压缩到了原点，变成了 0 向量，这时候变换 $A$ 发生了空间压缩，行列式为 0，那么这整条线上的向量都为它的解，有非零解。

假如它是 2x3 的矩阵，也就是把一个 3 维空间通过线性变换变成 2 维空间，很显然在变换的过程中，空间被压缩了，压缩过程中必有非 0 向量被压缩到了原点，因此方程有非零解。

![](https://img.hwenyi.live/202409061758181.webp)

同样 $A·\vec{X}=\vec{B}$ 也可以理解为向量 $\vec{X}$ 通过 $A$ 线性变换变为向量 $\vec{B}$ 。

# 八、特征值与特征向量

矩阵代表的是一种线性变换，**特征向量**指的是在这种变换中仅仅是被拉伸或者压缩。**特征值**则是表示特征向量在变换中被拉伸或压缩比例的因子。另外，二维线性变换不一定有特征向量。

## 8-1：基变换

在二维空间中的向量 $\begin{bmatrix} 3\\2 \end{bmatrix}$ ，我们可以将其看作向量伸缩再相加的结果，比如把 $\hat{i}$ 即 $\begin{bmatrix} 1\\0 \end{bmatrix}$ 变长为 3 倍，把 $\hat{j}$ 即 $\begin{bmatrix} 0\\1 \end{bmatrix}$ 变长为 2 倍，再相加。

![](https://img.hwenyi.live/202409061758182.webp)

一个向量本没有坐标，之所以能够**把向量转换成一组坐标**，或者说**能把向量转换成一组有序的数，是因为我们设定了一个【坐标系】**。发生在向量与一组数之间的任意一种【**转化】**，都被称为一组**坐标系**。

之所以上面的向量表示为 $\begin{bmatrix} 3\\2 \end{bmatrix}$ ，是因为把$\hat{i}$ 伸长为 3 倍、把$\hat{j}$ 伸长为 2 倍，再相加的结果。

**平面中【任意】其他向量都可以表示为$\hat{i}$ 和** $\hat{j}$ **的有向【伸缩倍数】，此时$\hat{i}$ 和$\hat{j}$ 就被称为坐标系的【基向量】。**

本节主要介绍的是**基变换**的概念，顾名思义，基变换就是对基向量做变换！

假设我们的朋友詹妮弗使用另一组坐标系，即有另一组不同的基向量 $\vec{b_{1}}$ 和 $\vec{b_{2}}$ 。

![](https://img.hwenyi.live/202409061758183.webp)

那原先在我们的坐标系中 $\begin{bmatrix} 3\\2 \end{bmatrix}$ 的向量，使用詹妮弗坐标系的话，就不再是 $\begin{bmatrix} 3\\2 \end{bmatrix}$ 了，而是$\vec{b_{1}}$ 和 $\vec{b_{2}}$ 的缩放倍数，即 $\begin{bmatrix} \frac{5}{3}\\\frac{1}{3} \end{bmatrix}$ ；

![](https://img.hwenyi.live/202409061758184.webp)

那么$\begin{bmatrix} \frac{5}{3}\\\frac{1}{3} \end{bmatrix}$ 是如何计算得到的呢？先别急，往下看看，答案就在后面。

综上所述可知，**同一个向量，使用不同的坐标系，得到的坐标是完全不同的。**那么如何在不同的坐标系中进行坐标转换呢？

在詹妮佛的坐标系中，她的$\vec{b_{1}}$ 和 $\vec{b_{2}}$ 是 $\begin{bmatrix} 1\\0 \end{bmatrix}$ 和 $\begin{bmatrix} 0\\1 \end{bmatrix}$ ；

![](https://img.hwenyi.live/202409061758185.webp)

但在我们的坐标系中，$\vec{b_{1}}$ 和 $\vec{b_{2}}$ 分别是 $\begin{bmatrix} 2\\1 \end{bmatrix}$ 和 $\begin{bmatrix} -1\\1 \end{bmatrix}$ 。

![](https://img.hwenyi.live/202409061758186.webp)

假设在詹妮佛的坐标系中，有一个坐标是 $\begin{bmatrix} -1\\2 \end{bmatrix}$ 的向量，那么在我们的空间中，这个向量的坐标是什么呢？也就是说，如何在不同坐标系之间进行转化？

这个向量的坐标是 $-1*\vec{b_{1}}+2*\vec{b_{2}}$ ，而 $\vec{b_{1}}$ 和 $\vec{b_{2}}$ 在我们的坐标系中的坐标分别是 $\begin{bmatrix} 2\\1 \end{bmatrix}$ 和 $\begin{bmatrix} -1\\1 \end{bmatrix}$ ，因此结果是 $\begin{bmatrix} -4\\1 \end{bmatrix}$ 。

![](https://img.hwenyi.live/202409061758187.webp)

上面的过程用**矩阵相乘**来表示，即：

![](https://img.hwenyi.live/202409061758188.webp)

因为矩阵代表的是一种线性变换，所以 $\begin{bmatrix} 2&-1\\1&1 \end{bmatrix}$ 的意思可以理解为，将我们空间中的 $\begin{bmatrix} 1\\0 \end{bmatrix}$ 、 $\begin{bmatrix} 0\\1 \end{bmatrix}$ 转换到詹妮佛空间中的 $\begin{bmatrix} 1\\0 \end{bmatrix}$ 、 $\begin{bmatrix} 0\\1 \end{bmatrix}$ ，而詹妮佛空间中的 $\begin{bmatrix} 1\\0 \end{bmatrix}$ 、 $\begin{bmatrix} 0\\1 \end{bmatrix}$ ，在我们空间看的话，坐标分别是 $\begin{bmatrix} 2\\1 \end{bmatrix}$ 和 $\begin{bmatrix} -1\\1 \end{bmatrix}$ 。

因此将詹妮佛坐标系描述的一个向量坐标，转换为我们坐标系描述的坐标，只需要**左乘上这个矩阵**即可。

![](https://img.hwenyi.live/202409061758189.webp)

相反的，如果把我们坐标系下的一个向量的坐标，转换成詹妮佛坐标系下对应的坐标，应该是一个相反的过程，因此使用对应矩阵的逆。

![](https://img.hwenyi.live/202409061758190.webp)

例如，我们空间中的 $\begin{bmatrix} 3\\2 \end{bmatrix}$ 在詹妮佛坐标系下如何表示呢？

![](https://img.hwenyi.live/202409061758191.webp)

乘上相应的逆矩阵即可。

![](https://img.hwenyi.live/202409061758192.webp)

![](https://img.hwenyi.live/202409061758193.webp)

![](https://img.hwenyi.live/202409061758194.webp)

![](https://img.hwenyi.live/202409061758195.webp)

最后再总结一下上面的过程，首先分别定义了两个坐标系——我们的坐标系和詹妮佛的坐标系。

两个坐标系各有一组基向量，从各自的角度看，基向量的坐标都是 $\begin{bmatrix} 1\\0 \end{bmatrix}$ 和 $\begin{bmatrix} 0\\1 \end{bmatrix}$ ，但是在我们的坐标系中，詹妮佛的基向量对应的坐标分别是 $\begin{bmatrix} 2\\1 \end{bmatrix}$ 和 $\begin{bmatrix} -1\\1 \end{bmatrix}$ ，那么**詹妮佛定义的坐标系所描述的向量，若想用我们定义的坐标系来描述**，只需要左乘一个矩阵即可。该矩阵，即使用我们定义的坐标系，来描述詹妮佛的基向量矩阵时对应的矩阵。

![](https://img.hwenyi.live/202409061758196.webp)

逆矩阵则相反

![](https://img.hwenyi.live/202409061758197.webp)

更进一步，考虑一个旋转 90 度的线性变换，我们的基向量 $\begin{bmatrix} 1\\0 \end{bmatrix}$ 和 $\begin{bmatrix} 0\\1 \end{bmatrix}$ ，变换后的坐标分别是 $\begin{bmatrix} 0\\1 \end{bmatrix}$ 和 $\begin{bmatrix} -1\\0 \end{bmatrix}$ 。

![](https://img.hwenyi.live/202409061758198.webp)

那么在詹妮佛空间中如何表示同样的变换呢？是左乘 $\begin{bmatrix} 0&-1\\1&0 \end{bmatrix}$ 么？

![](https://img.hwenyi.live/202409061758199.webp)

答案是否定的，$\begin{bmatrix} 0&-1\\1&0 \end{bmatrix}$ 是在追踪我们所选的基向量的变化。

![](https://img.hwenyi.live/202409061758200.webp)

也就是说，把我们的坐标系旋转 90 度得到了另一个坐标系 b，坐标系 b 下的基向量用我们的坐标系表示的话是 $\begin{bmatrix} 0\\1 \end{bmatrix}$ 和 $\begin{bmatrix} -1\\0 \end{bmatrix}$ 。那么在詹妮佛的坐标系下，一个向量旋转 90 度后的坐标是什么呢？

比如詹妮佛坐标系下的坐标为 $\begin{bmatrix} -1\\2 \end{bmatrix}$ 的向量，首先用基变换矩阵转换到我们定义的坐标，然后再旋转 90 度，最后将所得结果左乘基变换矩阵的逆，进而变回到詹妮佛定义的坐标。

![](https://img.hwenyi.live/202409061758201.webp)

这三个矩阵的复合运算，所得的结果就是詹妮弗定义的线性变换矩阵。

![](https://img.hwenyi.live/202409061758202.webp)

因此，表达式$A^{-1}MA$ 暗示着一种数学上的**转移作用**，中间的矩阵代表一种**你所见的变换，**而外侧两个矩阵代表着转移作用。

![](https://img.hwenyi.live/202409061758203.webp)

其实，矩阵乘积仍然代表着同一个变换，只不过是最初对坐标系的定义不同而已。

## 8-2：特征向量与特征值

这一部分介绍的是线性代数中非常重要的一个概念——**特征向量与特征值**。

首先劝退一下直接看着部分内容的同学，你们需要先大致掌握以下部分的知识点，才能更好的理解接下来的内容。正如视频作者所言，**我们之所以对特征的东西感到疑惑，更多的是因为下列内容的基础薄弱，而不是 “特征向量” 与“特征值”这个概念本身有多复杂**。

![](https://img.hwenyi.live/202409061758204.webp)

前面介绍过，一个矩阵代表一种线性变换，考虑二维空间中的某个线性变换，它将 $\hat{i}$ 即 $\begin{bmatrix} 1\\0 \end{bmatrix}$ 变换到 $\begin{bmatrix} 3\\0 \end{bmatrix}$ 的位置，将 $\hat{j}$ 即 $\begin{bmatrix} 0\\1 \end{bmatrix}$ 变换到 $\begin{bmatrix} 1\\2 \end{bmatrix}$ 的位置，那么对应的矩阵就是 $\begin{bmatrix} 3&1\\0&2 \end{bmatrix}$ 。

![](https://img.hwenyi.live/202409061758205.webp)

在这个变换过程中，很多向量都离开了其原本所张成的空间，即所在的直线，但也**有一些向量在变换后，仍恰好落在原来的直线上。**

![](https://img.hwenyi.live/202409061758206.webp)

如上图所示，基向量 $\hat{i}$ 就落在了原来的直线即 $x$ 轴上，只不过是被拉长了三倍，同样的， $x$ 轴上的任何其他向量在经过变换后都只是被拉伸为原来的三倍，且方向不变。也就**意味着，矩阵对它的作用仅仅只是拉伸或者压缩而已，如同一个标量**。

![](https://img.hwenyi.live/202409061758207.webp)

其实，除了 $x$ 轴上的向量外，向量 $\begin{bmatrix} -1\\1 \end{bmatrix}$ 所在的直线上的向量在变换后仍在原来的直线上，只是长度被拉长了两倍。

![](https://img.hwenyi.live/202409061758208.webp)

OK，总结一下。在刚才的线性变换中，有两条直线上的向量，在变换后仍在其所处的直线上，只有长度和方向发生了改变。其余向量在变换中或多或少都有些旋转，从而离开了它张成的直线。

经过上面矩阵所代表的线性变换后，**两条位置不变的直线上的任意向量**，都可以称之为**特征向量。**每个特征向量都有一个所属的值，称之为 “**特征值**”，用于**衡量特征向量在线性变换中的拉伸或压缩程度**。

需要注意的是，如果线性变换后是反向伸缩，那么**特征值是负的；**

![](https://img.hwenyi.live/202409061758209.webp)

接下来介绍特征值和特征向量的计算方法，这对于我们接下来的概念理解至关重要！

首先根据刚才的介绍，一个矩阵 A 的特征向量，在经过这个矩阵所代表的线性变换之后，没有偏离其所张成的直线，而只是发生了伸缩或方向改变，所以首先可以写出下面的式子。

![](https://img.hwenyi.live/202409061758210.webp)

我们将所有式子移到等式左端后会发现，在规定 $\vec{v}$ 为非 0 向量的前提下，要想等式成立，意味着该矩阵对应的线性变换将空间**压缩到了更低的维度**，也就联想到了我们之前介绍的 “行列式” 的内容—— ${\rm det}(A-\lambda I)=0$ 。

![](https://img.hwenyi.live/202409061758211.webp)

以文章开头提到的矩阵 $\begin{bmatrix} 3&1\\0&2 \end{bmatrix}$ 为例，很容易求解出特征值是 2 或者 3。

![](https://img.hwenyi.live/202409061758212.webp)

特征值已经求出来了，那么如何求解对应的特征向量呢？

以特征值 2 为例，求解如下的方程组。你会发现，所有的解全部落在由 $\begin{bmatrix} -1\\1 \end{bmatrix}$ 张成的对角线上。

![](https://img.hwenyi.live/202409061758213.webp)

![](https://img.hwenyi.live/202409061758214.webp)

再回到文章开头提到的一个概念—— 二维线性变换不一定有特征向量。

比如说，下面描述的这个旋转矩阵，它并没有特征向量，因为每一个向量都发生了旋转，并离开了它最初张成的空间。

![](https://img.hwenyi.live/202409061758215.webp)

此时我们运用刚刚介绍的方法去求解其特征向量，你就发现并没有实数解，也就意味着它没有特征向量！

![](https://img.hwenyi.live/202409061758216.webp)

在这里还想提一个非常有意思的矩阵——剪切矩阵 $\begin{bmatrix} 1&1\\0&1 \end{bmatrix}$ ，通过计算以后我们会发现，所有 $x$ 轴上的向量都属于特征值为 1 的特征向量，因为他们都保持不变。

![](https://img.hwenyi.live/202409061758217.webp)

![](https://img.hwenyi.live/202409061758218.webp)

需要注意的是，**可能会出现只有一个特征值，但是特征向量不止在一条直线上的情况**！

如下面的矩阵将空间中所有的向量都拉伸了两倍，它只有一个特征值 2，但是所有的向量都是其特征向量。

![](https://img.hwenyi.live/202409061758219.webp)

![](https://img.hwenyi.live/202409061758220.webp)

## 8-3：特征基

最后，我将介绍一下与 “**特征基**” 有关的概念。

首先思考一个问题——如果我们的基向量都是特征向量，会发生什么？

假如我们的 $\hat{i}$ 变为原来的 $-1$ 倍， $\hat{j}$ 变为原来的 $2$ 倍，将它们的新坐标作为矩阵的列，那么我们会发现， $-1$ 和 $2$ 其实就是 $\hat{i}$ 和 $\hat{j}$ 的特征值！

![](https://img.hwenyi.live/202409061758221.webp)

解读对角矩阵的方法就是，所有的基向量都是特征向量，矩阵的对角元是它们对应的特征值。

![](https://img.hwenyi.live/202409061758222.webp)

对角矩阵有什么优点呢？其中，最重要的一个方面就是，**矩阵与自己多次相乘的结果更容易计算**，因为对角矩阵仅仅只让基向量与某个特征值相乘。

![](https://img.hwenyi.live/202409061758223.webp)

一般情况下，我们很难直接得到这样的对角矩阵，那我们应该怎么办呢？

如下图所示，假如我们已知的变换对应很多特征向量，多到我们能选出一个可以张成全空间的集合。那么，我们就可以**变换我们的坐标系**，使得这些特征向量就是我们的基向量。

![](https://img.hwenyi.live/202409061758224.webp)

上面提到了变换坐标系，其实也就是 8-1 中提到的 “基变换”，也就是说**我们需要在另一个坐标系中表达当前坐标系所描述的变换**。

**首先给定我们想用作新的基向量的坐标**，此处设定为 $\begin{bmatrix} 1\\0 \end{bmatrix}$ 和 $\begin{bmatrix} -1\\1 \end{bmatrix}$ ，也就是所谓的特征向量；

然后将两个坐标依次作为矩阵的列，**构成基变换矩阵** $\begin{bmatrix} 1&-1\\0&1 \end{bmatrix}$ ；

![](https://img.hwenyi.live/202409061758225.webp)

此时，我们所得的矩阵，其实代表的是同一个变换，但是，是用新的基向量所构成的坐标系来定义的。

用特征向量来完成这件事的意义在于，这个新矩阵必定为对角矩阵，且对角元即相应的特征值。这是因为，它所处的坐标系的基向量在变换中只进行了缩放。

![](https://img.hwenyi.live/202409061758226.webp)

从而，也就得到了以下这个定义—— **一组基向量（同样是特征向量）构成的集合被称为一组” 特征基 “**。

计算$\begin{bmatrix} 3&1\\0&2 \end{bmatrix}^{100}$ ，一种更容易的做法是先变换到特征基，计算 100 次幂，然后转化回标准系。

解

计算特征值和特征向量，得特征基变换矩阵 $\begin{bmatrix} 1&-1\\ 0&1 \end{bmatrix}$

![](https://img.hwenyi.live/202409061758227.webp)

并求出它的逆 $\begin{bmatrix} 1&-1\\0&1 \end{bmatrix}^{-1}= \begin{bmatrix} 1&1\\ 0&1 \end{bmatrix}$

对角化， $\begin{bmatrix} 1&-1\\0&1 \end{bmatrix}^{-1} \begin{bmatrix} 3&1\\0&2 \end{bmatrix} \begin{bmatrix} 1&-1\\0&1 \end{bmatrix}= \begin{bmatrix} 3&0\\0&2 \end{bmatrix}$

![](https://img.hwenyi.live/202409061758228.webp)

![](https://img.hwenyi.live/202409061758229.webp)

特征基下， $\begin{bmatrix} 3&0\\0&2 \end{bmatrix}^{100}= \begin{bmatrix} 3^{100}&0\\ 0&2^{100} \end{bmatrix}$

回到标准系，得 $\begin{bmatrix} 3&1\\0&2 \end{bmatrix}^{100}= \begin{bmatrix} 1&-1\\0&1 \end{bmatrix} \begin{bmatrix} 3^{100}&0\\0&2^{100} \end{bmatrix} \begin{bmatrix} 1&-1\\0&1 \end{bmatrix}^{-1}= \begin{bmatrix} 3^{100}&3^{100}-2^{100}\\0&2^{100} \end{bmatrix}$

![](https://img.hwenyi.live/202409061758230.webp)

## 8-4：矩阵的相似对角化

并非所有矩阵都能对角化，如剪切矩阵（特征向量不能张成全空间）。

![](https://img.hwenyi.live/202409061758231.webp)

![](https://img.hwenyi.live/202409061758232.webp)

充要条件分析

以上述剪切矩阵为例，特征值为 2 重根，但只对应 1 个特征向量，只有 1 个线性无关的特征向量，因此剪切矩阵**不能**相似对角化！

充分条件分析

剪切矩阵为 2 阶矩阵，但是特征值为 2 重根，因此只有 1 个不同的特征值，因此**推不出**矩阵可相似对角化！

剪切矩阵并非对称矩阵，故也**推不出**矩阵可相似对角化！

# 完结致辞

写于 22-09-30

本篇笔记历时近一月才完成，到今天也就要告一段落了。最开始的计划是准备把克拉默法则一起讲了的，但是克拉默法则并非考研的重点知识，所以我最后决定把这一部分内容删除。

本来打算把合同对角化以及二次型的内容加进来的，但是写着写着就觉得很别扭，感觉和之前的内容完全不在一个知识体系，我无法像串联从前的知识点一样，有机地把它们联系起来。但是我相信，有了前面这一部分内容的铺垫，大家对线代的学习一定会有崭新的认知，再去学习后续的内容也一定会比之前轻松很多。

当然了，二次型这部分其实才是重点考察的地方，这也就意味着，**它背后的逻辑分析一定程度上没有应试技巧重要**，我们在理解了最基础的那部分内容后，**仍然需要通过大量的练习，来巩固之前的知识点**，以及学习后续的内容。我也会一直陪着大家努力，继续分享自己的学习笔记和人生观点，让我们都能以最好的姿态走进今年的考场，共同实现彼此的理想！